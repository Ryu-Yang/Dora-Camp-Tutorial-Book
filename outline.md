
# 目录

- [第1章 引言]()
  - [1.1 具身智能简介]()
  - [1.2 具身智能技术方向]()
  - [1.3 具身智能应用方向]() 
  - [1.4 Dora与具身智能]() 

智能篇

- [第2章 大模型训练与微调]()
  - [2.1 模型种类与结构]()
  - [2.2 训练算法]()
  - [2.3 微调方法]()
  - [2.4 使用LLaMA-Factory进行模型微调]()
  - [2.5 微调评估测试]()

- [第3章 语音识别]()
  - [3.1 基本架构]()
  - [3.2 声学模型(Acoustic Model)]()
  - [3.3 语言模型]()
  - [3.4 解码]()
  - [3.5 搭建识别模型]()
  - [3.6 模型优化与评测]()

- [第4章 GPT-SoVITS 语音合成]()
  - [4.1 相关理论研究]()
  - [4.2 原理架构]()
  - [4.3 推理用文本前端]()
  - [4.4 WebUI 工具]()
  - [4.3 训练数据处理]()
  - [4.4 训练和推理]()

- [第5章 基于BERT的情绪识别]()
  - [5.1 BERT模型简介]()
  - [5.2 情绪识别任务概述]()
  - [5.3 实验设计与结果分析]()

- [第6章 制作一位能对话的AI角色]()
  - [6.1 UE5游戏引擎介绍]()
  - [6.2 AI角色对话系统设计]()
  - [6.3 实现与测试]()

- [第7章 具身智能仿真平台]()
  - [7.1 Habitat 平台]()
  - [7.2 仿真平台架构]()
  - [7.3 平台使用操作]()
  - [7.4 搭建仿真机器人]()

具身篇

- [第8章 Dora Kit开发套件详细介绍]()
  - [8.1 Dora Kit组件概述]()
  - [8.2 硬件接口与功能]()
  - [8.3 机器人基础]()

- [第9章 线下实验环境配置](./lab0/README_zh.md)
  - [9.1 硬件需求]()
  - [9.2 Rust 开发环境配置]()
  - [9.3 conda安装和Python虚拟环境配置]()
  - [9.4 VSCode安装]()
  - [9.5 CUDA安装]()
  - [9.6 Dora和rerun安装]()
  - [9.7 大模型推理环境配置]()
  - [9.8 安装Nodes Hub内所有相关node]()
  - [9.9 网络与通信设置]()

- [第10章 通过Dora驱动机器人](./lab1/README_zh.md)
  - [10.1 基于Rust的机器人开发框架-Dora]()
  - [10.2 Dora数据流]()
  - [10.3 关键节点构建]()
  - [10.4 实际操作演示]()

- [第11章 OpenCV实现智能控制]()
  - [11.1 OpenCV基础]()
  - [11.2 机械臂自动抓取]()
  - [11.3 小车自动跟踪](./lab2/README_zh.md)

- [第12章 通过姿态识别控制机械臂]()
  - [12.1 姿态识别算法]()
  - [12.2 姿态映射到机械臂控制]()

- [第13章 视觉语言模型驱动的具身机器人](./lab3/README_zh.md)
  - [13.1 视觉语言模型-VLM介绍]()
  - [13.2 空间可视化工具-Rerun]()
  - [13.3 Qwen2-VL模型]()
  - [13.4 具身机器人系统架构]()
  - [13.5 实际应用场景与效果展示]()

- [第14章 具身智能机器人的数据采集与微调](./lab4/README_zh.md)
  - [14.1 数据采集方法]()
  - [14.2 数据预处理]()
  - [14.3 模型微调]()


# 本书涉及到的开源项目

- LLaMA-Factory 项目链接：[https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) 开源协议：`Apache-2`

- GPT-SoVITS 项目链接：[https://github.com/RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS) 开源协议：`MIT`



